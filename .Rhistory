g <- g + geom_point(mapping = aes(x=mpg , y = yhat))
g
ggplot(fit1, aes(x=mpg, y=am)) + geom_line()
g
g <- ggplot(data = mtcars , aes(x = mpg , y = am , col = factor(am)))
g = g + geom_point()
g = g + geom_boxplot()
g
g
yhat <- predict(fit1)
g = g + geom_line(mapping = aes(x=mpg , y = yhat))
g
ggplot(mtcars, aes(x=mpg, y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
cor(mtcars)
cor(mtcars)[1,]
fit2 <- glm(am ~ mpg + cyl + wt + hp - 1 , family = "binomial" , data = mtcars)
summary(fit2)
ggplot(mtcars, aes(x=mpg + cyl + wt + hp, y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
fit3 <- glm(am ~ mpg + wt , family = "binomial" , data = mtcars)
summary(fit3)
ggplot(mtcars, aes(x=mpg + cyl + wt + hp, y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
fit3 <- glm(am ~ mpg + wt , family = "binomial" , data = mtcars)
summary(fit3)
ggplot(mtcars, aes(x=mpg + wt , y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
fit3 <- glm(am ~ mpg + wt , family = "binomial" , data = mtcars)
summary(fit3)
ggplot(mtcars, aes(x=mpg + wt , y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
fit2 <- glm(am ~ mpg + cyl + wt + hp + disp - 1 , family = "binomial" , data = mtcars)
summary(fit2)
fit2 <- glm(am ~ mpg + cyl + wt + hp + disp - 1 , family = "binomial" , data = mtcars)
summary(fit2)
fit2 <- glm(am ~ mpg + cyl + wt + hp  - 1 , family = "binomial" , data = mtcars)
summary(fit2)
anova(fit1,fit2,fit3)
ggplot(mtcars, aes(x=mpg + cyl + wt + hp + disp , y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
ggplot(mtcars, aes(x=mpg + cyl + wt + hp  , y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
yhat <- predict(fit2)
yhat <- predict(fit2)
yhat
yhat <- predict(fit2)
plot(yhat)
yhat <- predict(fit2)
lines(yhat)
yhat <- predict(fit2)
lines(mpg + cyl + wt + hp,yhat)
yhat <- predict(fit2)
lines(mpg ,yhat)
modelChi <- fit1$null.deviance - fit1$deviance
psuedo.R <- modelChi /fit1$null.deviance
psuedo.R
modelChi <- fit2$null.deviance - fit2$deviance
psuedo.R <- modelChi /fit1$null.deviance
psuedo.R
fit2 <- glm(am ~ mpg + cyl + wt + hp  - 1 , family = "binomial" , data = mtcars)
summary(fit2)
modelChi <- fit2$null.deviance - fit2$deviance
psuedo.R <- modelChi /fit1$null.deviance
psuedo.R
modelChi <- fit3$null.deviance - fit3$deviance
psuedo.R <- modelChi /fit1$null.deviance
psuedo.R
ggplot(mtcars, aes(x=mpg, y=am)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) +
ylab("transmission")
g <- ggplot(data = mtcars , aes(x = mpg , y = am , col = factor(am)))
g = g + geom_point()
g = g + geom_boxplot()
g
g + geom_abline(fit2)
g + geom_abline(aes(fit2))
anova(fit1,fit2,fit3)
fit3 <- glm(am ~ mpg + wt - 1 , family = "binomial" , data = mtcars)
summary(fit3)
mpg_odds <- exp(coef(fit2)[1])
wt_odds <- exp(coef(fit2)[2])
mpg_odds,wt_odds
mpg_odds <- exp(coef(fit2)[1])
wt_odds <- exp(coef(fit2)[2])
mpg_odds
wt_odds
source('~/.active-rstudio-document')
head(training)
hist(Superplasticizer)
hist(concrete$Superplasticizer)
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
trainingil <- training[, grep("^IL", names(training))]
trainingil
proc <- preProcess(trainingil , method = "pca" , thresh = 0.9)
proc
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
trainingil <- training[,grep("^IL" , names(training))]
testil <- testing[,grep('IL', names(training))]
md1 <- train(diagnosis ~ . , data = trainingil, method = "glm")
md2 <- train(diagnosis ~ . , data = trainingil , method = "glm" , proProcess = "pca",
trcontrol = rainControl(preProcOptions=list(thresh=0.8)))
predict_md1 <- predict(md1 , newdata = testil)
trainingil <- training[,grep("^IL|diagnosis" , names(training))]
testil <- testing[,grep('^IL|diagnosis', names(training))]
md1 <- train(diagnosis ~ . , data = trainingil, method = "glm")
md2 <- train(diagnosis ~ . , data = trainingil , method = "glm" , proProcess = "pca",
trcontrol = rainControl(preProcOptions=list(thresh=0.8)))
predict_md1 <- predict(md1 , newdata = testil)
source('~/.active-rstudio-document')
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# grep all columns with IL and diagnosis in the traning and testing set
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- testing[,grep("^IL|diagnosis", names(testing))]
# non-PCA
model <- train(diagnosis ~ ., data = trainingIL, method = "glm")
predict_model <- predict(model, newdata= testingIL)
matrix_model <- confusionMatrix(predict_model, testingIL$diagnosis)
matrix_model$overall[1]
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
head(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p = 0.6,list = F)
training <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- train(Class ~ . , method = "rpart" , data = training)
source('~/.active-rstudio-document')
install.packages("e1071")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
install.packages("rattle")
model$finalMod
fancyRpartPlot(model$finalModel)
library(rpart.plot)
fancyRpartPlot(model$finalModel)
library(rpart)
fancyRpartPlot(model$finalModel)
source('~/.active-rstudio-document')
install.packages("pgmm")
source('~/.active-rstudio-document')
model <- train(Area ~ . , method = "rpart", data = olive)
predict(model , newdata = newdata)
source('~/.active-rstudio-document')
install.packages("ElemStatLearn")
source('~/.active-rstudio-document')
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("gbm")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
head(training)
source('~/.active-rstudio-document')
mod_rf <- train(diagnosis ~ . , method = "rf" , data = training)
mod_rf <- train(diagnosis ~ . , method = "rf" , data = training)
mod_gbm <- train(diagnosis ~ . , method = "gbm" , data = training)
mod_lda <- train(diagnosis ~ . , method = "lda" , data = training)
source('~/.active-rstudio-document')
pred_rf <- predict(mod_rf,newdata = testing)
pred_gbm <- predict(mod_gbm,newdata = testing)
pred_lda <- predict(mod_lda,newdata = testing)
confusionMatrix(pred_rf,testing$diagnosis)$overall["Accuracy"]
confusionMatrix(pred_gbm,testing$diagnosis)$overall["Accuracy"]
confusionMatrix(pred_lda,testing$diagnosis)$overall["Accuracy"]
pred_df <- data.frame(pred_rf,pred_gbm,pred_lda , diagnosis = testing$diagnosis)
combFit <- train(diagnosis ~ . , method = "rf" , data = pred_df)
combPred <- predict(combFit , pred_df)
confusionMatrix(combPred,testing$diagnosis)$overall["Accuracy"]
source('~/.active-rstudio-document')
library(gbm)
library(caret)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ . , method = "rf" , data = training)
mod_gbm <- train(diagnosis ~ . , method = "gbm" , data = training)
mod_lda <- train(diagnosis ~ . , method = "lda" , data = training)
pred_rf <- predict(mod_rf,newdata = testing)
pred_gbm <- predict(mod_gbm,newdata = testing)
pred_lda <- predict(mod_lda,newdata = testing)
confusionMatrix(pred_rf,testing$diagnosis)$overall["Accuracy"]
confusionMatrix(pred_gbm,testing$diagnosis)$overall["Accuracy"]
confusionMatrix(pred_lda,testing$diagnosis)$overall["Accuracy"]
pred_df <- data.frame(pred_rf,pred_gbm,pred_lda , diagnosis = testing$diagnosis)
combFit <- train(diagnosis ~ . , method = "rf" , data = pred_df)
combPred <- predict(combFit , pred_df)
confusionMatrix(combPred,testing$diagnosis)$overall["Accuracy"]
library(gbm)
library(caret)
library(randomForest)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ . , method = "rf" , data = training)
mod_gbm <- train(diagnosis ~ . , method = "gbm" , data = training)
mod_lda <- train(diagnosis ~ . , method = "lda" , data = training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength ~ . , method = "lasso", data = training)
set.seed(3523)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength ~ . , method = "lasso", data = training)
plot.enet(model$finalModel,xvar = "penalty" , use.color = TRUE)
?plot.enet
set.seed(3523)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength ~ . , method = "lasso", data = training)
plot.enet(model$finalModel,xvar = "penalty" , use.color = TRUE)
library(elasticnet)
plot.enet(model$finalModel,xvar = "penalty" , use.color = TRUE)
install.packages("lubridate")
install.packages("lubridate")
install.packages("lubridate")
install.packages("lubridate")
install.packages("lubridate")
set.seed(3523)
library(caret)
library(elasticnet)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength ~ . , method = "lasso", data = training)
plot.enet(model$finalModel,xvar = "penalty" , use.color = TRUE)
library(lubridate) # For year() function below
dat = read.csv("~/Documents/R_tut/gaData.csv")
dat = read.csv("C:/Users/Documents/R_tut/gaData.csv")
dat = read.csv("/R_tut/gaData.csv")
dat = read.csv("gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Document/gaData.csv")
dat = read.csv("gaData.csv")
library(lubridate) # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
model <- bats(tstrain)
library(lubridate)# For year() function below
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model <- bats(tstrain)
plot(tstrain,xlab="time", ylab="visits")
fcast <- forecast(modFit, h=nrow(testing))
plot(fcast)
fcast <- forecast(model, h=nrow(testing))
plot(fcast)
fcast_lower95 = fcast$lower[,2]
fcast_upper95 = fcast$upper[,2]
table( (testing$visitsTumblr>fcast_lower95) & (testing$visitsTumblr<fcast_upper95) )
set.seed(3523)
library(e1071)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- svm(CompressiveStrength ~ . , data = training)
pred_svm <- predict(model, newdata = testing)
accuracy(pred_svm , testing$CompressiveStrength)
install.packages("parallel")
install.packages("doparallel")
yes
install.packages("doParallel")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(randomForest)
library(gbm)
library(parallel)
library(doParallel)
knitr::opts_chunk$set(echo = TRUE)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
dim(training)
dim(testing)
training <- training[ , colSums(is.na(training)) == 0]
dim(training)
sum(is.na(training))
library(caret)
library(randomForest)
library(gbm)
library(parallel)
library(doParallel)
cluster <- makeCluster(ddetectCores() - 1)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster())
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster())
setwd("~/R_project")
knitr::opts_chunk$set(echo = TRUE)
training = read.csv("pml-training.csv",na.strings = c("", "NA"))
testing = read.csv("pml-testing.csv",na.strings = c("", "NA"))
dim(training)
dim(testing)
training <- training[ , colSums(is.na(training)) == 0]
testing <- testing[, names(training[,-60])]
dim(training)
dim(testing)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 4)
registerDoParallel(cluster)
set.seed(1234)
val <- createDataPartition(training$classe , p = 0.8)[[1]]
training_set <- training[val,]
validation_set <- training[-val,]
dim(training_set)
dim(validation_set)
fit_control<-trainControl(method = "cv" ,number = 5,allowParallel=TRUE)
model1 <- train(classe ~ . , method = "rf" ,trControl = fit_control, data = training_set, verbose = T , preProcess = "pca")
model1
stopCluster(cluster)
registerDoSEQ()
prediction1 <- predict(model1 , newdata = validation_set)
confusionMatrix(prediction1 , validation_set$classe)
prediction1 <- predict(model1 , newdata = validation_set)
#confusionMatrix(prediction1 , validation_set$classe)
prediction1 <- predict(model1 , newdata = validation_set)
#confusionMatrix(prediction1 , validation_set$classe)
prediction1
prediction1 <- predict(model1 , newdata = validation_set)
#confusionMatrix(prediction1 , validation_set$classe)
dim(prediction1)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
training = read.csv("pml-training.csv",na.strings = c("", "NA"))
testing = read.csv("pml-testing.csv",na.strings = c("", "NA"))
dim(training)
dim(testing)
training <- training[ , colSums(is.na(training)) == 0]
training_set <- training[,-c(1:8)]
testing_set <- testing[,names(training_set[,-52])]
dim(training_set)
dim(testing_set)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 4)
registerDoParallel(cluster)
set.seed(1234)
val <- createDataPartition(training$classe , p = 0.75)[[1]]
training_set <- training[val,]
validation_set <- training[-val,]
dim(training_set)
dim(validation_set)
set.seed(1234)
val <- createDataPartition(training_set$classe , p = 0.75)[[1]]
new_training_set <- training_set[val,]
validation_set <- training_set[-val,]
dim(training_set)
dim(validation_set)
set.seed(1234)
val <- createDataPartition(training_set$classe , p = 0.75)[[1]]
new_training_set <- training_set[val,]
validation_set <- training_set[-val,]
dim(training_set)
dim(validation_set)
set.seed(1234)
val <- createDataPartition(training_set$classe , p = 0.75)[[1]]
new_training_set <- training_set[val,]
validation_set <- training_set[-val,]
dim(new_training_set)
dim(validation_set)
knitr::opts_chunk$set(echo = TRUE)
training = read.csv("pml-training.csv",na.strings = c("", "NA"))
testing = read.csv("pml-testing.csv",na.strings = c("", "NA"))
dim(training)
dim(testing)
training <- training[ , colSums(is.na(training)) == 0]
training_set <- training[,-c(1:8)]
testing_set <- testing[,names(training_set[,-52])]
dim(training_set)
dim(testing_set)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 4)
registerDoParallel(cluster)
set.seed(1234)
val <- createDataPartition(training_set$classe , p = 0.75)[[1]]
new_training_set <- training_set[val,]
validation_set <- training_set[-val,]
dim(new_training_set)
dim(validation_set)
fit_control<-trainControl(method = "cv" ,number = 5,allowParallel=TRUE)
model1 <- train(classe ~ . , method = "rf" ,trControl = fit_control, data = training_set, verbose = T , preProcess = "pca")
model1
stopCluster(cluster)
registerDoSEQ()
prediction1 <- predict(model1 , newdata = validation_set)
confusionMatrix(prediction1 , validation_set$classe)
prediction1 <- predict(model1 , newdata = validation_set)
confusionMatrix(prediction1 , validation_set$classe)
validation_set$classe
fit_control<-trainControl(method = "cv" ,number = 5,allowParallel=TRUE)
model1 <- train(classe ~ . , method = "rf" ,trControl = fit_control, data = new_training_set, verbose = T , preProcess = "pca")
knitr::opts_chunk$set(echo = TRUE)
training = read.csv("pml-training.csv",na.strings = c("", "NA"))
testing = read.csv("pml-testing.csv",na.strings = c("", "NA"))
dim(training)
dim(testing)
training <- training[ , colSums(is.na(training)) == 0]
training_set <- training[,-c(1:8)]
testing_set <- testing[,names(training_set[,-52])]
dim(training_set)
dim(testing_set)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 4)
registerDoParallel(cluster)
set.seed(1234)
intrain <- createDataPartition(training_set$classe , p = 0.75)[[1]]
new_training_set <- training_set[intrain,]
validation_set <- training_set[-intrain,]
dim(new_training_set)
dim(validation_set)
fit_control<-trainControl(method = "cv" ,number = 5,allowParallel=TRUE)
model1 <- train(classe ~ . , method = "rf" ,trControl = fit_control, data = new_training_set, verbose = F )
model1
stopCluster(cluster)
registerDoSEQ()
prediction1 <- predict(model1 , newdata = validation_set)
confusionMatrix(prediction1 , validation_set$classe)
prediction1 <- predict(model1 , newdata = validation_set)
confusionMatrix(prediction1 , as.factor(validation_set$classe))
confusionMatrix(prediction1, validation_set$classe)$overall[[1]]
confusionMatrix(prediction1, as.factor(validation_set$classe)$overall[[1]]
confusionMatrix(prediction1, as.factor(validation_set$classe))$overall[[1]]
prediction_test<- predict(model1 , newdata = testing)
prediction_test
